{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alternative-stick",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stupid-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-prerequisite",
   "metadata": {},
   "source": [
    "<h1>Data path and classes</h1>\n",
    "<p>Lets specifiy the data path and see how many classes we got in data set</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "wooden-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "train_audio_path = \"../../data\"\n",
    "labels = os.listdir(train_audio_path)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "classes = list(le.classes_)\n",
    "y = np_utils.to_categorical(y, num_classes = len(labels))\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-marshall",
   "metadata": {},
   "source": [
    "<h1>Reading data and resizeing</h1>\n",
    "<p>We read all data and resize them to one size, if some one fails to resize we simply ignore it, sixe by side we print the number of datapoints that got resized successfully.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed:1484\n",
      "bird:1521\n",
      "cat:1515\n",
      "dog:1547\n",
      "down:2152\n",
      "eight:2111\n",
      "five:2161\n",
      "four:2158\n"
     ]
    }
   ],
   "source": [
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    r = 0\n",
    "    for wav in waves:\n",
    "        try:\n",
    "            samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
    "            samples = librosa.resample(samples, sample_rate, 8000)\n",
    "            if(len(samples) == 8000) : \n",
    "                r += 1\n",
    "                all_wave.append(samples)\n",
    "                all_label.append(label)\n",
    "        except:\n",
    "            pass\n",
    "    print(f'{label}:{r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "immune-litigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(all_label)\n",
    "classes = list(le.classes_)\n",
    "y = np_utils.to_categorical(y, num_classes = len(classes))\n",
    "\n",
    "print(classes)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-london",
   "metadata": {},
   "source": [
    "<h1>Splitting data into test and train</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ethical-plymouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58250,)\n"
     ]
    }
   ],
   "source": [
    "#all_wave = np.array(all_wave).reshape(-1, 8000, 1)\n",
    "print(np.array(all_label).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wave = np.array(all_wave).reshape(-1, 8000, 1)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-alaska",
   "metadata": {},
   "source": [
    "<h1>Defining the CNN Model</h1>\n",
    "<p>We are using <a href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network\" target=\"_blank\">CNN</a> model for training  upon data to predict labels</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prostate-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "def create_model():\n",
    "    inputs = Input(shape=(8000,1))\n",
    "    \n",
    "    #First Conv1D layer\n",
    "    conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    \n",
    "    #Second Conv1D layer\n",
    "    conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    \n",
    "    #Third Conv1D layer\n",
    "    conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    \n",
    "    #Fourth Conv1D layer\n",
    "    conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "    conv = MaxPooling1D(3)(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    \n",
    "    #Flatten layer\n",
    "    conv = Flatten()(conv)\n",
    "    \n",
    "    #Dense Layer 1\n",
    "    conv = Dense(256, activation='relu')(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    \n",
    "    #Dense Layer 2\n",
    "    conv = Dense(128, activation='relu')(conv)\n",
    "    conv = Dropout(0.3)(conv)\n",
    "    \n",
    "    outputs = Dense(len(labels), activation='softmax')(conv)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-affair",
   "metadata": {},
   "source": [
    "<h1>Train Model</h1>\n",
    "<p>This funtion trains and returns the model, and have an optional argument <b>from_scratch</b> if set to true, it will train the model from scratch or elsewise will use the already avaible model to retrain and return, by default it is set to false</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "olive-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(from_scratch = False):\n",
    "    if(from_scratch or not os.path.exists('best_model.hdf5')):\n",
    "        model = create_model()\n",
    "        print('Model created')\n",
    "    else:\n",
    "        model = load_model('best_model.hdf5')\n",
    "        print('Model loaded')\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10, min_delta = 0.0001)\n",
    "    mc = ModelCheckpoint('best_model.hdf5', monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n",
    "    model.fit(x_train, y_train , epochs = 100, callbacks = [es, mc], batch_size = 32, validation_data = (x_valid, y_valid))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-indian",
   "metadata": {},
   "source": [
    "<h1>Load Model</h1>\n",
    "<p>This method simply returns the already trained model. <small style=\"color:red\">(Throws error if no model found)</small></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "satellite-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainded_model():\n",
    "    model = load_model('best_model.hdf5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-myrtle",
   "metadata": {},
   "source": [
    "<h1>Get Model</h1>\n",
    "<p>This method is responsible for generating the model and is exposed as api in .py file of docker container, it accepts the parameter <b>already_trained</b> if set to true it uses the already trained model else starts training the new one</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "filled-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46600, 8000, 1)\n",
      "(46600,)\n",
      "two\n",
      "(11650, 8000, 1)\n",
      "(11650,)\n"
     ]
    }
   ],
   "source": [
    "def get_model(already_trained = True):\n",
    "    global model\n",
    "    model =  load_trainded_model() if already_trained else train_model()\n",
    "\n",
    "#Send false if want to retrain model\n",
    "#get_model(False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_train[0])\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-complexity",
   "metadata": {},
   "source": [
    "<h1>Predict Function</h1>\n",
    "<p>This function inputs an array of float as audio and its sample rate and outputs the most likely value of it, it is also exposed as an api in docker.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sought-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(audio, sample_rate):\n",
    "    audio = np.array(audio, dtype=np.float32)\n",
    "    audio = librosa.resample(audio, sample_rate, 8000)\n",
    "    prob = model.predict(audio.reshape(1,8000,1))\n",
    "    index = np.argmax(prob[0])\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-whale",
   "metadata": {},
   "source": [
    "<h1>Lets predict!</h1>\n",
    "<p>Here we simply try to predict an input<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breathing-silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: bed\n"
     ]
    }
   ],
   "source": [
    "audio, sample_rate = librosa.load('./data/bed/00f0204f_nohash_0.wav', sr = 16000)\n",
    "print(\"Predicted Label:\", predict(audio, sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-desperate",
   "metadata": {},
   "source": [
    "<h1>End üêç</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-bulgaria",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspd",
   "language": "python",
   "name": "dspd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
