{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Imports and Initializations</h1>\n",
    "<ul>\n",
    "<li><b>dataset_id</b> is the id of the google bigQuery database</li>\n",
    "<li><b>table</b> is the id of the google biqQuery database table</li>\n",
    "<li><b>bicket_name</b> is the name of the google bucket</li>\n",
    "<li><b>root</b> is the name of the google bucket location</li>\n",
    "</ul>\n",
    "<p>Actuall data is in google bucket but we will be using biqQuery to handle it</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "dataset_id = 'dspd_aftabkhalil_dataset'\n",
    "#change with 'sounds' to download complete data\n",
    "table_id = 'sounds_sample'\n",
    "\n",
    "bucket_name = \"dspd_aftabkhalil_bucket\"\n",
    "\n",
    "#change with 'data' to download complete data\n",
    "#Do not add ./ before root here\n",
    "root = 'data_sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Method to execute any query on bigQuery</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    client = bigquery.Client()\n",
    "    query_job = client.query(query)\n",
    "    data = query_job.result()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get the types of resources from bigQuery database</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resource_types():\n",
    "    query = f'SELECT type FROM {dataset_id}.{table_id} group by type;'\n",
    "    result = run_query(query)\n",
    "    resource_types = []\n",
    "    for r in list(result):\n",
    "        resource_types.append(r.get('type'))\n",
    "    return resource_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get resources from biqQuery database</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resources(root, resource_type):\n",
    "    query = (f'SELECT name FROM {dataset_id}.{table_id} '\n",
    "             f'WHERE type = \"{resource_type}\" AND location LIKE \"{root}/{resource_type}/%\" '\n",
    "             f'GROUP BY name')\n",
    "    result = run_query(query)\n",
    "    resource = []\n",
    "    for r in list(result):\n",
    "        resource.append(r.get('name'))\n",
    "    return resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get google bucket</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket already exixts dspd_aftabkhalil_bucket in US with storage class STANDARD\n"
     ]
    }
   ],
   "source": [
    "def create_or_get_bucket(bucket_name):\n",
    "    \n",
    "    #Create storage client\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    #Get already existsing buckets\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    \n",
    "    #Check if required bucket already exists\n",
    "    bucket = next((b for b in buckets if b.name == bucket_name), None)\n",
    "    \n",
    "    #If bucket already exists retuen it\n",
    "    if(bucket != None):\n",
    "        print(f'Bucket already exixts {bucket.name} in {bucket.location} with storage class {bucket.storage_class}')\n",
    "        return bucket\n",
    "    #Else create and return bucket\n",
    "    else:\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        new_bucket = storage_client.create_bucket(bucket, location=\"us\")\n",
    "        print(f'Created bucket {new_bucket.name} in {new_bucket.location} with storage class {new_bucket.storage_class}')\n",
    "        return new_bucket\n",
    "\n",
    "_ = create_or_get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Function to download resource from google bucket</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "def download_blob(resource_full_path):\n",
    "    blob = bucket.blob(resource_full_path)\n",
    "    blob.download_to_filename(resource_full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Lets Download!</h1>\n",
    "<p>Note that data will actually be downloaded if it not exists locally or forse_download is set to True</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 30 types in dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd10262e5ea42ceabf346f3a9c59619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete\n"
     ]
    }
   ],
   "source": [
    "def download_dataset(root, force_download = False):\n",
    "    resource_types = get_resource_types()\n",
    "    resource_types.sort()\n",
    "    \n",
    "    max_count = len(resource_types)\n",
    "    \n",
    "    print(f'There are a total of {max_count} types in dataset')    \n",
    "    uploadBar = IntProgress(min = 0, max = max_count)\n",
    "    display(uploadBar)   \n",
    "    \n",
    "    for resource_type in resource_types:\n",
    "        folder = f'{root}/{resource_type}'\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        \n",
    "        remote_resources = get_resources(root, resource_type)\n",
    "        \n",
    "        for remote_resource in remote_resources:\n",
    "            resource_full_path = f'{root}/{resource_type}/{remote_resource}'\n",
    "            if(force_download or not os.path.exists(f'{resource_full_path}')):\n",
    "                download_blob(resource_full_path)\n",
    "                \n",
    "        #We increment the progress when one class is downloaded\n",
    "        uploadBar.value += 1\n",
    "                \n",
    "download_dataset(root)\n",
    "print(\"Download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Wait for the above block to print \"Download complete\" üêç</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspd",
   "language": "python",
   "name": "dspd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
